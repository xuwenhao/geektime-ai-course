{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "\n",
      "Human: 你是谁？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 我是中国厨师，我可以帮助您制作中国菜肴。我有很多口味，比如酸辣粉、麻辣烫、红烧肉等等。我会根据您的口味和偏好，帮您做出最美味的中国菜肴。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "template = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "memory = ConversationBufferWindowMemory(memory_key=\"chat_history\", k=3)\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(), \n",
    "    prompt=prompt, \n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "llm_chain.predict(human_input=\"你是谁？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是中国厨师，我可以帮助您制作中国菜肴。我有很多口味，比如酸辣粉、麻辣烫、红烧肉等等。我会根据您的口味和偏好，帮您做出最美味的中国菜肴。\n",
      "Human: 鱼香肉丝怎么做？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是中国厨师，我可以帮助您制作中国菜肴。我有很多口味，比如酸辣粉、麻辣烫、红烧肉等等。我会根据您的口味和偏好，帮您做出最美味的中国菜肴。\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:  鱼香肉丝是一道经典的家常菜，做法很简单，首先准备好肉丝和鱼香肉丝料，然后将肉丝炒香，加入葱蒜爆香，再加入鱼香肉丝料拌匀，最后加入精盐、醋等调味料，最后淋上鸡蛋液和葱花，就可以上桌了。\n",
      "Human: 那宫保鸡丁呢？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是中国厨师，我可以帮助您制作中国菜肴。我有很多口味，比如酸辣粉、麻辣烫、红烧肉等等。我会根据您的口味和偏好，帮您做出最美味的中国菜肴。\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:  鱼香肉丝是一道经典的家常菜，做法很简单，首先准备好肉丝和鱼香肉丝料，然后将肉丝炒香，加入葱蒜爆香，再加入鱼香肉丝料拌匀，最后加入精盐、醋等调味料，最后淋上鸡蛋液和葱花，就可以上桌了。\n",
      "Human: 那宫保鸡丁呢？\n",
      "AI:  宫保鸡丁是一道非常受欢迎的传统中国菜肴，首先准备好鸡肉和宫保调料，然后将鸡肉切成小块，加入宫保调料拌匀，再将鸡丁炸至金黄色，最后加入葱花和花生米，即可上桌享用。\n",
      "Human: 我问你的第一句话是什么？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 我的第一句话是“你是谁？”'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"鱼香肉丝怎么做？\")\n",
    "llm_chain.predict(human_input=\"那宫保鸡丁呢？\")\n",
    "llm_chain.predict(human_input=\"我问你的第一句话是什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:  鱼香肉丝是一道经典的家常菜，做法很简单，首先准备好肉丝和鱼香肉丝料，然后将肉丝炒香，加入葱蒜爆香，再加入鱼香肉丝料拌匀，最后加入精盐、醋等调味料，最后淋上鸡蛋液和葱花，就可以上桌了。\n",
      "Human: 那宫保鸡丁呢？\n",
      "AI:  宫保鸡丁是一道非常受欢迎的传统中国菜肴，首先准备好鸡肉和宫保调料，然后将鸡肉切成小块，加入宫保调料拌匀，再将鸡丁炸至金黄色，最后加入葱花和花生米，即可上桌享用。\n",
      "Human: 我问你的第一句话是什么？\n",
      "AI:  我的第一句话是“你是谁？”\n",
      "Human: 我问你的第一句话是什么？\n",
      "Chatbot:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 我的第一句话是“鱼香肉丝怎么做？”'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"我问你的第一句话是什么？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: 那宫保鸡丁呢？\\nAI:  宫保鸡丁是一道非常受欢迎的传统中国菜肴，首先准备好鸡肉和宫保调料，然后将鸡肉切成小块，加入宫保调料拌匀，再将鸡丁炸至金黄色，最后加入葱花和花生米，即可上桌享用。\\nHuman: 我问你的第一句话是什么？\\nAI:  我的第一句话是“你是谁？”\\nHuman: 我问你的第一句话是什么？\\nAI:  我的第一句话是“鱼香肉丝怎么做？”'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "\n",
      "Human: 你好\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 你好，我是一个中国厨师，我喜欢做中国菜，比如红烧肉、宫保鸡丁、鱼香肉丝等。我会用新鲜的食材，精心烹饪，让每一道菜都美味可口。'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "llm = OpenAI(temperature=0)\n",
    "memory = ConversationSummaryMemory(llm=OpenAI())\n",
    "\n",
    "prompt_template = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文\n",
    "2. 回答限制在100个字以内\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=prompt_template\n",
    ")\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary.predict(input=\"你好\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文\n",
      "2. 回答限制在100个字以内\n",
      "\n",
      "\n",
      "The human greeted the AI, to which the AI replied that it was a Chinese chef that enjoyed making Chinese dishes such as braised pork, Kung Pao chicken, and Fish-fragrant pork shreds. The AI also said that it would use fresh ingredients and carefully cook each dish to make them delicious.\n",
      "Human: 鱼香肉丝怎么做？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 鱼香肉丝是一道很受欢迎的中国菜，需要准备肉丝、葱、姜、蒜、辣椒、花椒、酱油、糖、醋、料酒、淀粉等食材。先将肉丝用淀粉、料酒、盐、胡椒粉腌制，然后炒锅里放入葱、姜、蒜、辣椒、花椒爆香，加入肉丝翻炒，最后加入酱油、糖、醋、淀粉调味即可。'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"鱼香肉丝怎么做？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': '\\nThe human greeted the AI, to which the AI replied that it was a Chinese chef that enjoyed making Chinese dishes such as braised pork, Kung Pao chicken, and Fish-fragrant pork shreds. The AI also said that it would use fresh ingredients and carefully cook each dish to make them delicious. When the human asked about how to make Fish-fragrant pork shreds, the AI replied that it needed to prepare ingredients such as meat shreds, scallions, ginger, garlic, peppers, Sichuan pepper, soy sauce, sugar, vinegar, cooking wine, and cornstarch. The AI then explained that the meat shreds should first be marinated with cornstarch, cooking wine, salt, and pepper, and then the scallions, ginger, garlic, and peppers should be stir-fried in a wok, followed by the addition of the meat shreds. Finally, soy sauce, sugar, vinegar, and cornstarch should be added to season the dish.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"那蚝油牛肉呢？\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 我是一个中国厨师，可以帮助你做菜。\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "SUMMARIZER_TEMPLATE = \"\"\"请将以下内容逐步概括所提供的对话内容，并将新的概括添加到之前的概括中，形成新的概括。\n",
    "\n",
    "EXAMPLE\n",
    "Current summary:\n",
    "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量。\n",
    "\n",
    "New lines of conversation:\n",
    "Human：为什么你认为人工智能是一种积极的力量？\n",
    "AI：因为人工智能将帮助人类发挥他们的潜能。\n",
    "\n",
    "New summary:\n",
    "Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。\n",
    "END OF EXAMPLE\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "New lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:\"\"\"\n",
    "\n",
    "SUMMARY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"new_lines\"], template=SUMMARIZER_TEMPLATE\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=256)\n",
    "\n",
    "CHEF_TEMPLATE = \"\"\"你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
    "1. 你的回答必须是中文。\n",
    "2. 对于做菜步骤的回答尽量详细一些。\n",
    "\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "CHEF_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=CHEF_TEMPLATE\n",
    ")\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=OpenAI(model_name=\"text-davinci-003\", stop=\"\\n\\n\", max_tokens=2048, temperature=0.5), \n",
    "    prompt=CHEF_PROMPT,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "answer = conversation_with_summary.predict(input=\"你是谁？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "Human: 你是谁？\n",
      "AI:  我是一个中国厨师，可以帮助你做菜。\n",
      "Human: 请问鱼香肉丝怎么做？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 鱼香肉丝是一道很受欢迎的中国菜，需要准备的材料有：猪肉、葱、姜、蒜、酱油、料酒、糖、醋、花椒粉、胡椒粉、淀粉、芡汁、鸡蛋、花生油和香菜。首先，将猪肉切成薄片，加入料酒、盐、胡椒粉、淀粉、芡汁拌匀，腌制半小时。然后，炒锅中加入适量油，将葱、姜、蒜爆香，加入猪肉片翻炒，加入酱油、糖、醋、花椒粉、胡椒粉翻炒均匀，最后加入香菜、花生油和鸡蛋拌匀即可。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"请问鱼香肉丝怎么做？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "System: \n",
      "Human询问AI身份，AI回答自己是一个中国厨师，可以帮助Human做菜。Human问鱼香肉丝怎么做，AI介绍了准备的材料和制作步骤。\n",
      "Human: 那蚝油牛肉呢？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 蚝油牛肉是一道经典的家常菜，准备材料有牛肉、蚝油、葱、姜、八角、花椒、料酒、盐、糖等。首先将牛肉切成薄片，然后用盐、糖、料酒腌制牛肉片；热锅，放入蚝油、葱、姜、八角、花椒爆香，加入腌制好的牛肉片，翻炒均匀，最后加入适量的水，放入盐、糖调味，煮至牛肉熟透即可。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"那蚝油牛肉呢？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m你是一个中国厨师，用中文回答做菜的问题。你的回答需要满足以下要求:\n",
      "1. 你的回答必须是中文。\n",
      "2. 对于做菜步骤的回答尽量详细一些。\n",
      "\n",
      "System: \n",
      "Human询问AI身份，AI回答自己是一个中国厨师，可以帮助Human做菜。Human问鱼香肉丝怎么做，AI介绍了准备的材料和制作步骤，Human又问蚝油牛肉，AI也介绍了准备的材料和制作步骤。\n",
      "Human: 宫保鸡丁和软炸里脊哪个好吃？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 宫保鸡丁和软炸里脊都是很受欢迎的菜肴，口味和口感都不相同，可以根据自己的喜好选择。宫保鸡丁是一道比较常见的家常菜，主要由鸡肉、胡萝卜、葱、蒜、花生米等材料制作而成，步骤是：首先将鸡肉切成小块，然后加入盐、料酒、白胡椒粉、鸡精腌制；把胡萝卜、葱、蒜切成末；将花生米炒香；将腌制好的鸡肉放入油锅中炸至金黄色；最后加入胡萝卜、葱、蒜末，加入适量的鸡汤，翻炒均匀，即可出锅。软炸里脊是一道比较经典的家常菜，主要由里脊肉、葱、姜、蒜、鸡蛋等材料制作而成，步骤是：首先将里脊肉切成小块，然后加入盐、料酒、白胡椒粉、鸡精腌制；把葱、姜、蒜切成末；将鸡蛋打入碗中，加入盐、料酒、白胡椒粉搅拌均匀；将腌制好的里脊肉放入油锅中炸至金黄色；最后加入葱姜蒜末，加入鸡蛋液，搅拌均匀，即可出锅。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_summary.predict(input=\"宫保鸡丁和软炸里脊哪个好吃？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: \\nHuman询问AI身份，AI回答自己是一个中国厨师，可以帮助Human做菜。Human问鱼香肉丝怎么做，AI介绍了准备的材料和制作步骤，Human又问蚝油牛肉，AI也介绍了准备的材料和制作步骤；Human还问宫保鸡丁和软炸里脊哪个好吃，AI回答宫保鸡丁和软炸里脊都是很受欢迎的菜肴，口味'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationKGMemory\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"], template=template\n",
    ")\n",
    "kg_memory = ConversationKGMemory(llm=llm)\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    prompt=prompt,\n",
    "    memory=kg_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: 你好\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: 我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单，但是暂时还没有收到货。我会尽快查询货物的运输情况，并及时通知你。\n"
     ]
    }
   ],
   "source": [
    "answer = conversation_with_kg.predict(input=\"你好\")\n",
    "print(answer)\n",
    "answer = conversation_with_kg.predict(input=\"我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseModel.json of ConversationKGMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='你好', additional_kwargs={}), AIMessage(content=' 你好！很高兴见到你。我是一个AI，我可以回答你的问题。你想问我什么？', additional_kwargs={}), HumanMessage(content='我叫徐文浩，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是还没有收到货', additional_kwargs={}), AIMessage(content=' 嗨徐文浩，很高兴认识你！我看到你的订单号是2023ABCD，你的邮箱地址是customer@abc.com。我确认你的订单，但是暂时还没有收到货。我会尽快查询货物的运输情况，并及时通知你。', additional_kwargs={})]), output_key=None, input_key=None, return_messages=False, k=2, human_prefix='Human', ai_prefix='AI', kg=<langchain.graphs.networkx_graph.NetworkxEntityGraph object at 0x7fefc09abac0>, knowledge_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template=\"You are a networked intelligence helping a human track knowledge triples about all relevant people, things, concepts, etc. and integrating them with your knowledge stored within your weights as well as that stored in a knowledge graph. Extract all of the knowledge triples from the last line of conversation. A knowledge triple is a clause that contains a subject, a predicate, and an object. The subject is the entity being described, the predicate is the property of the subject that is being described, and the object is the value of the property.\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Did you hear aliens landed in Area 51?\\nAI: No, I didn't hear that. What do you know about Area 51?\\nPerson #1: It's a secret military base in Nevada.\\nAI: What do you know about Nevada?\\nLast line of conversation:\\nPerson #1: It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\nOutput: (Nevada, is a, state)<|>(Nevada, is in, US)<|>(Nevada, is the number 1 producer of, gold)\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: Hello.\\nAI: Hi! How are you?\\nPerson #1: I'm good. How are you?\\nAI: I'm good too.\\nLast line of conversation:\\nPerson #1: I'm going to the store.\\n\\nOutput: NONE\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: What do you know about Descartes?\\nAI: Descartes was a French philosopher, mathematician, and scientist who lived in the 17th century.\\nPerson #1: The Descartes I'm referring to is a standup comedian and interior designer from Montreal.\\nAI: Oh yes, He is a comedian and an interior designer. He has been in the industry for 30 years. His favorite food is baked bean pie.\\nLast line of conversation:\\nPerson #1: Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\nOutput: (Descartes, likes to drive, antique scooters)<|>(Descartes, plays, mandolin)\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:\", template_format='f-string', validate_template=True), entity_extraction_prompt=PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I\\'m working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7fefe05de020>, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False), summary_message_cls=<class 'langchain.schema.SystemMessage'>, memory_key='history')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.memory.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EntityMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 您好，张老三，感谢您下订单，我们会尽快处理您的订单。我们会尽快将您的订单发货，如果您有任何疑问，请随时联系我们，我们会尽快给您回复。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "\n",
    "entityMemory = ConversationEntityMemory(llm=llm)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=entityMemory\n",
    ")\n",
    "\n",
    "answer=conversation.predict(input=\"我叫张老三，在你们这里下了一张订单，订单号是 2023ABCD，我的邮箱地址是 customer@abc.com，但是这个订单十几天了还没有收到货\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'张老三': '张老三是一位客户，订单号为2023ABCD，邮箱地址为customer@abc.com。', '2023ABCD': '2023ABCD is an order placed by Zhang Lao San with the email address customer@abc.com that has not yet been received after more than ten days.', 'customer@abc.com': 'Email address of Zhang Lao San, who placed an order with us with order number 2023ABCD.'}\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 您的订单号是2023ABCD。\n"
     ]
    }
   ],
   "source": [
    "answer=conversation.predict(input=\"我刚才的订单号是多少？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 订单2023ABCD是您张老三的订单，您的邮箱地址是customer@abc.com。\n"
     ]
    }
   ],
   "source": [
    "answer=conversation.predict(input=\"订单2023ABCD是谁的订单？\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
