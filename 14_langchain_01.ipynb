{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多次调用完成中译英，英文文答，英译中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please introduce the principle of CNN as an expert in machine learning.\n",
      "\n",
      "\n",
      "Convolutional Neural Networks (CNNs) are a type of deep learning neural network that is used for image and video analysis. CNNs are inspired by the structure of the brain and are composed of multiple layers of neurons, each layer performing a different task. The layers of a CNN typically include convolutional layers, pooling layers, and fully connected layers. The convolutional layers are responsible for extracting features from the input data, while the pooling layers reduce the dimensionality of the data. The fully connected layers are then used to classify the data. The overall goal of a CNN is to learn the features of an image and then classify them into different categories.\n",
      "\n",
      "\n",
      "卷积神经网络（CNN）是一种深度学习神经网络，用于图像和视频分析。 CNN受到大脑结构的启发，由多层神经元组成，每层执行不同的任务。 CNN的层通常包括卷积层，池层和完全连接层。卷积层负责从输入数据中提取特征，而池层则减少数据的维数。然后使用完全连接的层来对数据进行分类。 CNN的总体目标是学习图像的特征，然后将它们分类到不同的类别中。\n"
     ]
    }
   ],
   "source": [
    "import openai, os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", max_tokens=2048, temperature=0.5)\n",
    "\n",
    "en_to_zh_prompt = PromptTemplate(\n",
    "    template=\"请把下面这句话翻译成英文： \\n\\n {question}?\", input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    template = \"{english_question}\", input_variables=[\"english_question\"]\n",
    ")\n",
    "\n",
    "zh_to_cn_prompt = PromptTemplate(\n",
    "    input_variables=[\"english_answer\"],\n",
    "    template=\"请把下面这一段翻译成中文： \\n\\n{english_answer}?\",\n",
    ")\n",
    "\n",
    "\n",
    "question_translate_chain = LLMChain(llm=llm, prompt=en_to_zh_prompt, output_key=\"english_question\")\n",
    "english = question_translate_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
    "print(english)\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=question_prompt, output_key=\"english_answer\")\n",
    "english_answer = qa_chain.run(english_question=english)\n",
    "print(english_answer)\n",
    "\n",
    "answer_translate_chain = LLMChain(llm=llm, prompt=zh_to_cn_prompt)\n",
    "answer = answer_translate_chain.run(english_answer=english_answer)\n",
    "print(answer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Langchain简化实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "Please explain the principle of CNN as an expert in Machine Learning.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "A Convolutional Neural Network (CNN) is a type of deep learning algorithm that uses a series of convolutional layers to extract features from an input image. The layers are made up of neurons that are arranged in a 3-dimensional grid and connected to each other in a specific way. Each neuron is connected to a subset of the neurons in the previous layer and is responsible for extracting a specific feature from the input image. As the input image is passed through the layers, more complex features are extracted and used to classify the image. The key principle of CNNs is that they learn the features from the data, instead of having to be explicitly programmed. This allows the network to be trained on large datasets and to generalize well on unseen data.\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m\n",
      "\n",
      "卷积神经网络（CNN）是一种深度学习算法，它使用一系列卷积层从输入图像中提取特征。这些层由神经元组成，它们排列成三维网格，并以特定方式相互连接。每个神经元连接到前一层中的一个子集神经元，负责从输入图像中提取特定特征。随着输入图像通过层，提取更复杂的特征，用于对图像进行分类。CNN的关键原理是它们从数据中学习特征，而不必明确编程。这使得网络可以在大型数据集上进行训练，并能够很好地推广到看不见的数据。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "卷积神经网络（CNN）是一种深度学习算法，它使用一系列卷积层从输入图像中提取特征。这些层由神经元组成，它们排列成三维网格，并以特定方式相互连接。每个神经元连接到前一层中的一个子集神经元，负责从输入图像中提取特定特征。随着输入图像通过层，提取更复杂的特征，用于对图像进行分类。CNN的关键原理是它们从数据中学习特征，而不必明确编程。这使得网络可以在大型数据集上进行训练，并能够很好地推广到看不见的数据。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chinese_qa_chain = SimpleSequentialChain(\n",
    "    chains=[question_translate_chain, qa_chain, answer_translate_chain], input_key=\"question\",\n",
    "    verbose=True)\n",
    "answer = chinese_qa_chain.run(question=\"请你作为一个机器学习的专家，介绍一下CNN的原理。\")\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多步骤引入不同输入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "波尔图获得欧冠的次数更多，共计4次，而西班牙皇家马德里只有3次。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "q1_prompt = PromptTemplate(\n",
    "    input_variables=[\"year1\"],\n",
    "    template=\"{year1}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
    ")\n",
    "q2_prompt = PromptTemplate(\n",
    "    input_variables=[\"year2\"],\n",
    "    template=\"{year2}年的欧冠联赛的冠军是哪支球队，只说球队名称。\"\n",
    ")\n",
    "q3_prompt = PromptTemplate(\n",
    "    input_variables=[\"team1\", \"team2\"],\n",
    "    template=\"{team1}和{team2}哪只球队获得欧冠的次数多一些？\"\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt=q1_prompt, output_key=\"team1\")\n",
    "chain2 = LLMChain(llm=llm, prompt=q2_prompt, output_key=\"team2\")\n",
    "chain3 = LLMChain(llm=llm, prompt=q3_prompt)\n",
    "\n",
    "sequential_chain = SequentialChain(chains=[chain1, chain2, chain3], input_variables=[\"year1\", \"year2\"], verbose=True)\n",
    "answer = sequential_chain.run(year1=2000, year2=2010)\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过Langchain来完成自动撰写单元测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n",
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n",
      "WARNING! stop is not default parameter.\n",
      "                    stop was transfered to model_kwargs.\n",
      "                    Please confirm that stop is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "def format_time(seconds):\n",
      "    minutes, seconds = divmod(seconds, 60)\n",
      "    hours, minutes = divmod(minutes, 60)\n",
      "    if hours > 0:\n",
      "        return f\"{hours}h{minutes}min{seconds}s\"\n",
      "    elif minutes > 0:\n",
      "        return f\"{minutes}min{seconds}s\"\n",
      "    else:\n",
      "        return f\"{seconds}s\"\n",
      "#Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator.\n",
      "#The first element of the tuple is the name of the test case, and the second element is a list of tuples,\n",
      "#where each tuple contains the input values for the format_time() function and the expected output.\n",
      "@pytest.mark.parametrize(\"test_case, input_values, expected_output\", [\n",
      "    # Test cases for when the seconds parameter is an integer\n",
      "    (\"seconds is positive\", (42,), \"42s\"),\n",
      "    (\"seconds is negative\", (-42,), \"-42s\"),\n",
      "    (\"seconds is 0\", (0,), \"0s\"),\n",
      "    # Test cases for when the seconds parameter is not an integer\n",
      "    (\"seconds is a float\", (42.0,), \"42.0s\"),\n",
      "    (\"seconds is a string\", (\"42\",), \"42s\"),\n",
      "    (\"seconds is None\", (None,), \"None\"),\n",
      "    # Test cases for when the seconds parameter is an integer, but it is not in the range 0-3600\n",
      "    (\"seconds is too small\", (-1,), \"-1s\"),\n",
      "    (\"seconds is too large\", (3601,), \"1h0min1s\"),\n",
      "])\n",
      "def test_format_time(test_case, input_values, expected_output):\n",
      "    # We use the pytest.raises context manager to assert that the function raises a TypeError\n",
      "    # if the input is not an integer.\n",
      "    with pytest.raises(TypeError):\n",
      "        format_time(input_values)\n",
      "    # We use the pytest.approx context manager to assert that the output is approximately equal\n",
      "    # to the expected output, within a certain tolerance.\n",
      "    assert format_time(input_values) == pytest.approx(expected_output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "def write_unit_test(function_to_test, unit_test_package = \"pytest\"):\n",
    "    # 解释源代码的步骤\n",
    "    explain_code = \"\"\"\"# How to write great unit tests with {unit_test_package}\n",
    "\n",
    "    In this advanced tutorial for experts, we'll use Python 3.10 and `{unit_test_package}` to write a suite of unit tests to verify the behavior of the following function.\n",
    "    ```python\n",
    "    {function_to_test}\n",
    "    ```\n",
    "\n",
    "    Before writing any unit tests, let's review what each element of the function is doing exactly and what the author's intentions may have been.\n",
    "    - First,\"\"\"\n",
    "\n",
    "    explain_code_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\"],\n",
    "        template=explain_code\n",
    "    )\n",
    "    explain_code_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.4, max_tokens=1000, \n",
    "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
    "    explain_code_step = LLMChain(llm=explain_code_llm, prompt=explain_code_template, output_key=\"code_explaination\")\n",
    "\n",
    "\n",
    "    # 创建测试计划示例的步骤\n",
    "    test_plan = \"\"\"\n",
    "        \n",
    "    A good unit test suite should aim to:\n",
    "    - Test the function's behavior for a wide range of possible inputs\n",
    "    - Test edge cases that the author may not have foreseen\n",
    "    - Take advantage of the features of `{unit_test_package}` to make the tests easy to write and maintain\n",
    "    - Be easy to read and understand, with clean code and descriptive names\n",
    "    - Be deterministic, so that the tests always pass or fail in the same way\n",
    "\n",
    "    `{unit_test_package}` has many convenient features that make it easy to write and maintain unit tests. We'll use them to write unit tests for the function above.\n",
    "\n",
    "    For this particular function, we'll want our unit tests to handle the following diverse scenarios (and under each scenario, we include a few examples as sub-bullets):\n",
    "    -\"\"\"\n",
    "    test_plan_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\"],\n",
    "        template= explain_code + \"{code_explaination}\" + test_plan\n",
    "    )\n",
    "    test_plan_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.4, max_tokens=1000, \n",
    "            top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"])\n",
    "    test_plan_step = LLMChain(llm=test_plan_llm, prompt=test_plan_template, output_key=\"test_plan\")\n",
    "\n",
    "    # 撰写测试代码的步骤\n",
    "    starter_comment = \"Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator\"\n",
    "    prompt_to_generate_the_unit_test = \"\"\"\n",
    "\n",
    "Before going into the individual tests, let's first look at the complete suite of unit tests as a cohesive whole. We've added helpful comments to explain what each line does.\n",
    "```python\n",
    "import {unit_test_package}  # used for our unit tests\n",
    "\n",
    "{function_to_test}\n",
    "\n",
    "#{starter_comment}\"\"\"\n",
    "\n",
    "    unit_test_template = PromptTemplate(\n",
    "        input_variables=[\"unit_test_package\", \"function_to_test\", \"code_explaination\", \"test_plan\", \"starter_comment\"],\n",
    "        template= explain_code + \"{code_explaination}\" + test_plan + \"{test_plan}\" + prompt_to_generate_the_unit_test\n",
    "    )\n",
    "    unit_test_llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.4, max_tokens=1000, stop=\"```\")\n",
    "    unit_test_step = LLMChain(llm=unit_test_llm, prompt=unit_test_template, output_key=\"unit_test\")\n",
    "\n",
    "    sequential_chain = SequentialChain(chains=[explain_code_step, test_plan_step, unit_test_step], \n",
    "                                    input_variables=[\"unit_test_package\", \"function_to_test\", \"starter_comment\"], verbose=True)\n",
    "    answer = sequential_chain.run(unit_test_package=unit_test_package, function_to_test=function_to_test, starter_comment=starter_comment)\n",
    "    return f\"\"\"#{starter_comment}\"\"\" + answer\n",
    "\n",
    "\n",
    "code = \"\"\"\n",
    "def format_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "    if hours > 0:\n",
    "        return f\"{hours}h{minutes}min{seconds}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}min{seconds}s\"\n",
    "    else:\n",
    "        return f\"{seconds}s\"\n",
    "\"\"\"\n",
    "\n",
    "import ast\n",
    "\n",
    "def write_unit_test_automatically(code, retry=3):\n",
    "    unit_test_code = write_unit_test(code)\n",
    "    all_code = code + unit_test_code\n",
    "    tried = 0\n",
    "    while tried < retry:\n",
    "        try:\n",
    "            ast.parse(all_code)\n",
    "            return all_code\n",
    "        except SyntaxError as e:\n",
    "            print(f\"Syntax error in generated code: {e}\")\n",
    "            all_code = code + write_unit_test(code)\n",
    "            tried += 1\n",
    "\n",
    "print(write_unit_test_automatically(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
